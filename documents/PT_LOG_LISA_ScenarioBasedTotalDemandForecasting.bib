@article{SALINAS20201181,
	title = "DeepAR: Probabilistic forecasting with autoregressive recurrent networks",
	journal = "International Journal of Forecasting",
	volume = "36",
	number = "3",
	pages = "1181 - 1191",
	year = "2020",
	issn = "0169-2070",
	doi = "https://doi.org/10.1016/j.ijforecast.2019.07.001",
	url = "http://www.sciencedirect.com/science/article/pii/S0169207019301888",
	author = "David Salinas and Valentin Flunkert and Jan Gasthaus and Tim Januschowski",
	keywords = "Probabilistic forecasting, Neural networks, Deep learning, Big data, Demand forecasting",
	abstract = "Probabilistic forecasting, i.e., estimating a time series’ future probability distribution given its past, is a key enabler for optimizing business processes. In retail businesses, for example, probabilistic demand forecasts are crucial for having the right inventory available at the right time and in the right place. This paper proposes DeepAR, a methodology for producing accurate probabilistic forecasts, based on training an autoregressive recurrent neural network model on a large number of related time series. We demonstrate how the application of deep learning techniques to forecasting can overcome many of the challenges that are faced by widely-used classical approaches to the problem. By means of extensive empirical evaluations on several real-world forecasting datasets, we show that our methodology produces more accurate forecasts than other state-of-the-art methods, while requiring minimal manual work."
}

@article{DBLP:journals/corr/abs-1906-05264,
	author    = {Alexander Alexandrov and
	Konstantinos Benidis and
	Michael Bohlke{-}Schneider and
	Valentin Flunkert and
	Jan Gasthaus and
	Tim Januschowski and
	Danielle C. Maddix and
	Syama Sundar Rangapuram and
	David Salinas and
	Jasper Schulz and
	Lorenzo Stella and
	Ali Caner T{\"{u}}rkmen and
	Yuyang Wang},
	title     = {GluonTS: Probabilistic Time Series Models in Python},
	journal   = {CoRR},
	volume    = {abs/1906.05264},
	year      = {2019},
	url       = {http://arxiv.org/abs/1906.05264},
	archivePrefix = {arXiv},
	eprint    = {1906.05264},
	timestamp = {Mon, 17 Jun 2019 15:05:27 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1906-05264.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{zhou2019tweedie,
	title={Tweedie Gradient Boosting for Extremely Unbalanced Zero-inflated Data}, 
	author={He Zhou and Yi Yang and Wei Qian},
	year={2019},
	eprint={1811.10192},
	archivePrefix={arXiv},
	primaryClass={stat.CO}
}

@article{DBLP:journals/corr/Graves13,
	author    = {Alex Graves},
	title     = {Generating Sequences With Recurrent Neural Networks},
	journal   = {CoRR},
	volume    = {abs/1308.0850},
	year      = {2013},
	url       = {http://arxiv.org/abs/1308.0850},
	archivePrefix = {arXiv},
	eprint    = {1308.0850},
	timestamp = {Mon, 13 Aug 2018 16:47:21 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/Graves13.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/SutskeverVL14,
	author    = {Ilya Sutskever and
	Oriol Vinyals and
	Quoc V. Le},
	title     = {Sequence to Sequence Learning with Neural Networks},
	journal   = {CoRR},
	volume    = {abs/1409.3215},
	year      = {2014},
	url       = {http://arxiv.org/abs/1409.3215},
	archivePrefix = {arXiv},
	eprint    = {1409.3215},
	timestamp = {Mon, 13 Aug 2018 16:48:06 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/SutskeverVL14.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/ChenLLLWWXXZZ15,
	author    = {Tianqi Chen and
	Mu Li and
	Yutian Li and
	Min Lin and
	Naiyan Wang and
	Minjie Wang and
	Tianjun Xiao and
	Bing Xu and
	Chiyuan Zhang and
	Zheng Zhang},
	title     = {MXNet: {A} Flexible and Efficient Machine Learning Library for Heterogeneous
	Distributed Systems},
	journal   = {CoRR},
	volume    = {abs/1512.01274},
	year      = {2015},
	url       = {http://arxiv.org/abs/1512.01274},
	archivePrefix = {arXiv},
	eprint    = {1512.01274},
	timestamp = {Mon, 12 Oct 2020 13:57:53 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ChenLLLWWXXZZ15.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{rasul2020multivariate,
	title={Multi-variate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows}, 
	author={Kashif Rasul and Abdul-Saboor Sheikh and Ingmar Schuster and Urs Bergmann and Roland Vollgraf},
	year={2020},
	eprint={2002.06103},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{papamakarios2018masked,
	title={Masked Autoregressive Flow for Density Estimation}, 
	author={George Papamakarios and Theo Pavlakou and Iain Murray},
	year={2018},
	eprint={1705.07057},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}


@article{DBLP:journals/corr/DinhSB16,
	author    = {Laurent Dinh and
	Jascha Sohl{-}Dickstein and
	Samy Bengio},
	title     = {Density estimation using Real {NVP}},
	journal   = {CoRR},
	volume    = {abs/1605.08803},
	year      = {2016},
	url       = {http://arxiv.org/abs/1605.08803},
	archivePrefix = {arXiv},
	eprint    = {1605.08803},
	timestamp = {Mon, 13 Aug 2018 16:47:21 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/DinhSB16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{DBLP:journals/corr/GuoB16,
	author    = {Cheng Guo and
	Felix Berkhahn},
	title     = {Entity Embeddings of Categorical Variables},
	journal   = {CoRR},
	volume    = {abs/1604.06737},
	year      = {2016},
	url       = {http://arxiv.org/abs/1604.06737},
	archivePrefix = {arXiv},
	eprint    = {1604.06737},
	timestamp = {Mon, 13 Aug 2018 16:49:04 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/GuoB16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{M5Competition,
	author    = {University of Nicosia},
	title     = {The M5 Competition: Competitors' guide},
	year      = {2020},
	url       = {https://mk0mcompetitiont8ake.kinstacdn.com/wp-content/uploads/2020/02/M5-Competitors-Guide_Final-1.pdf}
}

@article{MAKRIDAKIS202054,
	title = "The M4 Competition: 100,000 time series and 61 forecasting methods",
	journal = "International Journal of Forecasting",
	volume = "36",
	number = "1",
	pages = "54 - 74",
	year = "2020",
	note = "M4 Competition",
	issn = "0169-2070",
	doi = "https://doi.org/10.1016/j.ijforecast.2019.04.014",
	url = "http://www.sciencedirect.com/science/article/pii/S0169207019301128",
	author = "Spyros Makridakis and Evangelos Spiliotis and Vassilios Assimakopoulos",
	keywords = "Forecasting competitions, M competitions, Forecasting accuracy, Prediction intervals, Time series methods, Machine learning methods, Benchmarking methods, Practice of forecasting",
	abstract = "The M4 Competition follows on from the three previous M competitions, the purpose of which was to learn from empirical evidence both how to improve the forecasting accuracy and how such learning could be used to advance the theory and practice of forecasting. The aim of M4 was to replicate and extend the three previous competitions by: (a) significantly increasing the number of series, (b) expanding the number of forecasting methods, and (c) including prediction intervals in the evaluation process as well as point forecasts. This paper covers all aspects of M4 in detail, including its organization and running, the presentation of its results, the top-performing methods overall and by categories, its major findings and their implications, and the computational requirements of the various methods. Finally, it summarizes its main conclusions and states the expectation that its series will become a testing ground for the evaluation of new methods and the improvement of the practice of forecasting, while also suggesting some ways forward for the field."
}

@inproceedings{10.5555/3044805.3045048,
	author = {Chapados, Nicolas},
	title = {Effective Bayesian Modeling of Groups of Related Count Time Series},
	year = {2014},
	publisher = {JMLR.org},
	abstract = {Time series of counts arise in a variety of forecasting applications, for which traditional models are generally inappropriate. This paper introduces a hierarchical Bayesian formulation applicable to count time series that can easily account for explanatory variables and share statistical strength across groups of related time series. We derive an efficient approximate inference technique, and illustrate its performance on a number of datasets from supply chain planning.},
	booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
	pages = {II–1395–II–1403},
	numpages = {9},
	location = {Beijing, China},
	series = {ICML'14}
}

@article{SNYDER2012485,
	title = "Forecasting the intermittent demand for slow-moving inventories: A modelling approach",
	journal = "International Journal of Forecasting",
	volume = "28",
	number = "2",
	pages = "485 - 496",
	year = "2012",
	issn = "0169-2070",
	doi = "https://doi.org/10.1016/j.ijforecast.2011.03.009",
	url = "http://www.sciencedirect.com/science/article/pii/S0169207011000781",
	author = "Ralph D. Snyder and J. Keith Ord and Adrian Beaumont",
	keywords = "Croston’s method, Exponential smoothing, Hurdle shifted Poisson distribution, Intermittent demand, Inventory control, Prediction likelihood, State space models",
	abstract = "Organizations with large-scale inventory systems typically have a large proportion of items for which demand is intermittent and low volume. We examine various different approaches to demand forecasting for such products, paying particular attention to the need for inventory planning over a multi-period lead-time when the underlying process may be non-stationary. This emphasis leads to the consideration of prediction distributions for processes with time-dependent parameters. A wide range of possible distributions could be considered, but we focus upon the Poisson (as a widely used benchmark), the negative binomial (as a popular extension of the Poisson), and a hurdle shifted Poisson (which retains Croston’s notion of a Bernoulli process for the occurrence of active demand periods). We also develop performance measures which are related to the entire prediction distribution, rather than focusing exclusively upon point predictions. The three models are compared using data on the monthly demand for 1046 automobile parts, provided by a US automobile manufacturer. We conclude that inventory planning should be based upon dynamic models using distributions that are more flexible than the traditional Poisson scheme."
}


@article{DBLP:journals/corr/ChungGCB14,
	author    = {Junyoung Chung and
	{\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
	KyungHyun Cho and
	Yoshua Bengio},
	title     = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence
	Modeling},
	journal   = {CoRR},
	volume    = {abs/1412.3555},
	year      = {2014},
	url       = {http://arxiv.org/abs/1412.3555},
	archivePrefix = {arXiv},
	eprint    = {1412.3555},
	timestamp = {Mon, 13 Aug 2018 16:47:38 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ChungGCB14.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/VaswaniSPUJGKP17,
	author    = {Ashish Vaswani and
	Noam Shazeer and
	Niki Parmar and
	Jakob Uszkoreit and
	Llion Jones and
	Aidan N. Gomez and
	Lukasz Kaiser and
	Illia Polosukhin},
	title     = {Attention Is All You Need},
	journal   = {CoRR},
	volume    = {abs/1706.03762},
	year      = {2017},
	url       = {http://arxiv.org/abs/1706.03762},
	archivePrefix = {arXiv},
	eprint    = {1706.03762},
	timestamp = {Mon, 13 Aug 2018 16:48:37 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}